# WhisperLiveKit Configuration
# Copy this to .env and customize for your deployment

# ===== Model Settings =====
WHISPER_MODEL=base
# Options: tiny, base, small, medium, large-v3, large-v3-turbo
# Smaller = faster, Larger = more accurate

WHISPER_LANGUAGE=auto
# Options: auto, en, es, fr, de, zh, ja, etc.
# Use "auto" for automatic detection

# ===== Features =====
ENABLE_DIARIZATION=true
# Enable speaker identification (who is speaking)
# Set to "false" for faster processing without speaker labels

TARGET_LANGUAGE=
# Leave empty for no translation
# Set to language code for translation: es, fr, de, etc.
# Example: TARGET_LANGUAGE=es (translate to Spanish)

# ===== Advanced Settings =====
WHISPER_DEVICE=cuda
# Options: cuda (GPU), cpu
# Use cuda for RunPod L40S

WHISPER_COMPUTE_TYPE=float16
# Options: float16 (GPU), int8 (CPU/low VRAM), int8_float16
# float16 is fastest on GPU

# ===== Performance Tuning =====
# Uncomment and adjust these if needed

# PRELOAD_MODEL_COUNT=1
# Number of model instances to preload (for multiple concurrent users)

# BACKEND=simulstreaming
# Options: simulstreaming (default), whisperstreaming
# simulstreaming is recommended for lowest latency

# PCM_INPUT=false
# Set to true to use raw PCM audio instead of WebM
# Requires AudioWorklet in frontend
